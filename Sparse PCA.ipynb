{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2d270a",
   "metadata": {},
   "source": [
    "# Sparse PCA Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cb63a",
   "metadata": {},
   "source": [
    "Let $$S_{p\\times p}=\\alpha[1\\ \\cdots\\ 1\\ 0\\ \\cdots\\ 0]^T[1\\ \\cdots\\ 1\\ 0\\ \\cdots\\ 0] + \\beta I_p$$ and $$(Z_{n\\times p})_{i, j}\\sim\\mathcal{N}(0, 1).$$\n",
    "We define $$X_{n,p}\\equiv Z_{n,p}S_{p,p}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39514e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 50\n",
    "n = 30\n",
    "alpha = 0.8\n",
    "beta = 0.2\n",
    "sparsity = 0.3\n",
    "sparse_vector = np.empty((p, 1))\n",
    "for i in range(p):\n",
    "    if i < p * sparsity:\n",
    "        sparse_vector[i][0] = 1\n",
    "    else:\n",
    "        sparse_vector[i][0] = 0\n",
    "S = alpha * sparse_vector @ sparse_vector.T + beta * np.identity(p)\n",
    "\n",
    "Z = np.empty((n, p))\n",
    "for i in range(n):\n",
    "    for j in range(p):\n",
    "        Z[i][j] = np.random.normal(0, 1)\n",
    "        \n",
    "X = Z @ S\n",
    "\n",
    "sparse_vector = torch.from_numpy(sparse_vector)\n",
    "S, Z, X = torch.from_numpy(S), torch.from_numpy(Z), torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape, Z.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790cd56",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-u(v\\odot w)^T\\rVert_F^2$$\n",
    "where for any matrix $A$, \n",
    "#### $$\\lVert A\\rVert_F^2 = \\sum_{i,j}A_{i,j}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(n, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_1(u, v, w):\n",
    "    A = X - u @ (v * w).T\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "step_size = 1e-4\n",
    "sine_errors = []\n",
    "l1 = []\n",
    "iterations = [*range(epochs + 1)]\n",
    "recovered = v.clone().detach() * w.clone().detach()\n",
    "cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "sine_errors.append(sine_error)\n",
    "l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_1(u, v, w)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    recovered = v.clone().detach() * w.clone().detach()\n",
    "    cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "    sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "    sine_errors.append(sine_error)\n",
    "    l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "    v.grad.zero_()\n",
    "    w.grad.zero_()\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_1(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors, label=\"sine_error\")\n",
    "plt.plot(iterations, l1, label=\"l1 norm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17738e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de0db53",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-Xu(v\\odot w)^T\\rVert_F^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(p, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ed225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_2(u, v, w):\n",
    "    A = X - (X.double() @ u.double()).double() @ (v * w).T.double()\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "step_size = 5e-7\n",
    "sine_errors = []\n",
    "l1 = []\n",
    "iterations = [*range(epochs + 1)]\n",
    "recovered = v.clone().detach() * w.clone().detach()\n",
    "cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "sine_errors.append(sine_error)\n",
    "l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_2(u, v, w)\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    recovered = v.clone().detach() * w.clone().detach()\n",
    "    cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "    sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "    sine_errors.append(sine_error)\n",
    "    l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_2(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7243c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18783ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors, label=\"sine_errors\")\n",
    "plt.plot(iterations, l1, label=\"l1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20777f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4828f",
   "metadata": {},
   "source": [
    "## Method 3\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-u(v\\odot v - w\\odot w)^T\\rVert_F^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc707f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(n, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927688d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_3(u, v, w):\n",
    "    A = X - u @ (v * v - w * w).T\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "step_size = 1e-4\n",
    "sine_errors = []\n",
    "l1 = []\n",
    "iterations = [*range(epochs + 1)]\n",
    "recovered = v.clone().detach() * v.clone().detach() - w.clone().detach() * w.clone().detach()\n",
    "cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "sine_errors.append(sine_error)\n",
    "l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_3(u, v, w)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    recovered = v.clone().detach() * v.clone().detach() - w.clone().detach() * w.clone().detach()\n",
    "    cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "    sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "    sine_errors.append(sine_error)\n",
    "    l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_3(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v * v - w * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors, label=\"sine_errors\")\n",
    "plt.plot(iterations, l1, label=\"l1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255360da",
   "metadata": {},
   "source": [
    "## Method 4\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-Xu(v\\odot v - w\\odot w)^T\\rVert_F^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(p, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9618a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_4(u, v, w):\n",
    "    A = X - X.double() @ u.double() @ (v * v - w * w).T.double()\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "step_size = 5e-7\n",
    "sine_errors = []\n",
    "l1 = []\n",
    "iterations = [*range(epochs + 1)]\n",
    "recovered = v.clone().detach() * v.clone().detach() - w.clone().detach() * w.clone().detach()\n",
    "cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "sine_errors.append(sine_error)\n",
    "l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_4(u, v, w)\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    recovered = v.clone().detach() * v.clone().detach() - w.clone().detach() * w.clone().detach()\n",
    "    cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "    sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "    sine_errors.append(sine_error)\n",
    "    l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_4(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v * v - w * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors, label=\"sine_errors\")\n",
    "plt.plot(iterations, l1, label=\"l1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202afc7b",
   "metadata": {},
   "source": [
    "### Hadamard Parametrization\n",
    "We want to maximize \n",
    "#### $$(u\\odot v)^TS(u\\odot v)$$\n",
    "where\n",
    "#### $$S=\\frac{1}{n}X^TX$$\n",
    "under the constraint\n",
    "#### $$\\lVert u\\odot v\\rVert = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce805a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(p, 1)\n",
    "v = torch.randn(p, 1)\n",
    "norm = torch.norm(u * v)\n",
    "u = u / (norm ** 0.5)\n",
    "v = v / (norm ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200000\n",
    "step_size = 1e-5\n",
    "sine_errors = []\n",
    "l1 = []\n",
    "iterations = [*range(epochs + 1)]\n",
    "recovered = u.clone().detach() * v.clone().detach()\n",
    "cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "sine_errors.append(sine_error)\n",
    "l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "for i in range(epochs):\n",
    "    if i % 1000 == 0:\n",
    "        objective = ((u * v).T.double() @ S.double() @ (u * v).double())[0][0]\n",
    "        print('Epoch ' + str(i) + \": objective = \" + str(float(objective)))\n",
    "    du = v.double() * ((S + S.T).double() @ (u * v).double())\n",
    "    dv = u.double() * ((S + S.T).double() @ (u * v).double())\n",
    "    u += du * step_size\n",
    "    v += dv * step_size\n",
    "    norm = torch.norm(u * v)\n",
    "    u = u / (norm ** 0.5)\n",
    "    v = v / (norm ** 0.5)\n",
    "    recovered = u.clone().detach() * v.clone().detach()\n",
    "    cosine_error = torch.sum(recovered * sparse_vector) / (torch.norm(recovered) * torch.norm(sparse_vector))\n",
    "    sine_error = (1 - cosine_error ** 2) ** 0.5\n",
    "    sine_errors.append(sine_error)\n",
    "    l1.append(float(torch.linalg.norm(recovered, ord=1)))\n",
    "objective = ((u * v).T.double() @ S.double() @ (u * v).double())[0][0]\n",
    "print('Epoch ' + str(epochs) + \": objective = \" + str(float(objective)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f43530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors, label=\"sine_errors\")\n",
    "plt.plot(iterations, l1, label=\"l1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca612d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, sine_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30a27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
