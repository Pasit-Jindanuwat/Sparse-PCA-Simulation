{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b2d270a",
   "metadata": {},
   "source": [
    "# Sparse PCA Simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b1cb63a",
   "metadata": {},
   "source": [
    "Let $$S_{p\\times p}=\\alpha[1\\ \\cdots\\ 1\\ 0\\ \\cdots\\ 0]^T[1\\ \\cdots\\ 1\\ 0\\ \\cdots\\ 0] + \\beta I_p$$ and $$(Z_{n\\times p})_{i, j}\\sim\\mathcal{N}(0, 1).$$\n",
    "We define $$X_{n,p}\\equiv Z_{n,p}S_{p,p}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8802a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39514e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 50\n",
    "n = 30\n",
    "alpha = 0.8\n",
    "beta = 0.2\n",
    "half = np.empty((p, 1))\n",
    "for i in range(p):\n",
    "    if i < p / 2:\n",
    "        half[i][0] = 1\n",
    "    else:\n",
    "        half[i][0] = 0\n",
    "S = alpha * half @ half.T + beta * np.identity(p)\n",
    "\n",
    "Z = np.empty((n, p))\n",
    "for i in range(n):\n",
    "    for j in range(p):\n",
    "        Z[i][j] = np.random.normal(0, 1)\n",
    "        \n",
    "X = Z @ S\n",
    "\n",
    "S, Z, X = torch.from_numpy(S), torch.from_numpy(Z), torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca9ae8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 50]), torch.Size([30, 50]), torch.Size([30, 50]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape, Z.shape, X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7790cd56",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-u(v\\odot w)^T\\rVert_F^2$$\n",
    "where for any matrix $A$, \n",
    "#### $$\\lVert A\\rVert_F^2 = \\sum_{i,j}A_{i,j}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abac69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(n, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471d0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_1(u, v, w):\n",
    "    A = X - u @ (v * w).T\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a498f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 9340.006853828141\n",
      "Epoch 100: loss = 5684.4451262344555\n",
      "Epoch 200: loss = 1156.293232515135\n",
      "Epoch 300: loss = 76.13295329702514\n",
      "Epoch 400: loss = 61.93265962788918\n",
      "Epoch 500: loss = 61.00041138227286\n",
      "Epoch 600: loss = 60.60948043873523\n",
      "Epoch 700: loss = 60.37601925948829\n",
      "Epoch 800: loss = 60.22104029625878\n",
      "Epoch 900: loss = 60.11112456848986\n",
      "Epoch 1000: loss = 60.02961601197364\n",
      "Epoch 1100: loss = 59.96727766155243\n",
      "Epoch 1200: loss = 59.91852477052376\n",
      "Epoch 1300: loss = 59.87971058021062\n",
      "Epoch 1400: loss = 59.84831807384053\n",
      "Epoch 1500: loss = 59.822531687423414\n",
      "Epoch 1600: loss = 59.80101516280337\n",
      "Epoch 1700: loss = 59.782760970148665\n",
      "Epoch 1800: loss = 59.76701234652928\n",
      "Epoch 1900: loss = 59.753205749059056\n",
      "Epoch 2000: loss = 59.740913936578615\n",
      "Epoch 2100: loss = 59.729832005457496\n",
      "Epoch 2200: loss = 59.719730763550295\n",
      "Epoch 2300: loss = 59.710455849802536\n",
      "Epoch 2400: loss = 59.7018963997779\n",
      "Epoch 2500: loss = 59.693981124149545\n",
      "Epoch 2600: loss = 59.68666443826202\n",
      "Epoch 2700: loss = 59.679917482580166\n",
      "Epoch 2800: loss = 59.67371238037659\n",
      "Epoch 2900: loss = 59.668043864172716\n",
      "Epoch 3000: loss = 59.66288794738202\n",
      "Epoch 3100: loss = 59.65823394091237\n",
      "Epoch 3200: loss = 59.65405719272262\n",
      "Epoch 3300: loss = 59.65033703870257\n",
      "Epoch 3400: loss = 59.64703954787235\n",
      "Epoch 3500: loss = 59.64414274674805\n",
      "Epoch 3600: loss = 59.64160715192441\n",
      "Epoch 3700: loss = 59.63939934964587\n",
      "Epoch 3800: loss = 59.637487711092525\n",
      "Epoch 3900: loss = 59.63583269248747\n",
      "Epoch 4000: loss = 59.63440693076668\n",
      "Epoch 4100: loss = 59.63317963328675\n",
      "Epoch 4200: loss = 59.632121447285215\n",
      "Epoch 4300: loss = 59.63121090270785\n",
      "Epoch 4400: loss = 59.63042353672935\n",
      "Epoch 4500: loss = 59.62974031266478\n",
      "Epoch 4600: loss = 59.629144720684025\n",
      "Epoch 4700: loss = 59.628624405488196\n",
      "Epoch 4800: loss = 59.62816586407689\n",
      "Epoch 4900: loss = 59.62775846371623\n",
      "Epoch 5000: loss = 59.62739544052638\n",
      "Epoch 5100: loss = 59.62706773592447\n",
      "Epoch 5200: loss = 59.626770252101\n",
      "Epoch 5300: loss = 59.62649830020365\n",
      "Epoch 5400: loss = 59.62624879040477\n",
      "Epoch 5500: loss = 59.62601683077585\n",
      "Epoch 5600: loss = 59.62580129465\n",
      "Epoch 5700: loss = 59.62559864644341\n",
      "Epoch 5800: loss = 59.625407438532875\n",
      "Epoch 5900: loss = 59.625225307419385\n",
      "Epoch 6000: loss = 59.6250530423912\n",
      "Epoch 6100: loss = 59.624887728855654\n",
      "Epoch 6200: loss = 59.62473030733851\n",
      "Epoch 6300: loss = 59.62457885655804\n",
      "Epoch 6400: loss = 59.62443348114624\n",
      "Epoch 6500: loss = 59.62429321672002\n",
      "Epoch 6600: loss = 59.6241569002926\n",
      "Epoch 6700: loss = 59.624025735017014\n",
      "Epoch 6800: loss = 59.623897960919585\n",
      "Epoch 6900: loss = 59.623774188128735\n",
      "Epoch 7000: loss = 59.62365409833393\n",
      "Epoch 7100: loss = 59.62353694253342\n",
      "Epoch 7200: loss = 59.62342336392957\n",
      "Epoch 7300: loss = 59.62331209851121\n",
      "Epoch 7400: loss = 59.62320334817694\n",
      "Epoch 7500: loss = 59.62309746565919\n",
      "Epoch 7600: loss = 59.62299404819441\n",
      "Epoch 7700: loss = 59.622892869315464\n",
      "Epoch 7800: loss = 59.62279362565703\n",
      "Epoch 7900: loss = 59.62269686469672\n",
      "Epoch 8000: loss = 59.62260231474308\n",
      "Epoch 8100: loss = 59.62250973829342\n",
      "Epoch 8200: loss = 59.6224181689639\n",
      "Epoch 8300: loss = 59.62232888829337\n",
      "Epoch 8400: loss = 59.62224135372241\n",
      "Epoch 8500: loss = 59.62215524213994\n",
      "Epoch 8600: loss = 59.62207034263189\n",
      "Epoch 8700: loss = 59.62198696178263\n",
      "Epoch 8800: loss = 59.62190507339996\n",
      "Epoch 8900: loss = 59.62182445077916\n",
      "Epoch 9000: loss = 59.6217451012056\n",
      "Epoch 9100: loss = 59.62166821670465\n",
      "Epoch 9200: loss = 59.62159141760151\n",
      "Epoch 9300: loss = 59.62151556722863\n",
      "Epoch 9400: loss = 59.621440922147286\n",
      "Epoch 9500: loss = 59.62136702122287\n",
      "Epoch 9600: loss = 59.62129453614937\n",
      "Epoch 9700: loss = 59.62122285090334\n",
      "Epoch 9800: loss = 59.621151962590844\n",
      "Epoch 9900: loss = 59.621082816231265\n",
      "Epoch 10000: loss = 59.62101377700445\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "step_size = 1e-4\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_1(u, v, w)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_1(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e47cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0151e+00],\n",
      "        [ 2.0660e+00],\n",
      "        [ 2.0426e+00],\n",
      "        [ 1.9659e+00],\n",
      "        [ 2.0037e+00],\n",
      "        [ 1.9751e+00],\n",
      "        [ 2.0061e+00],\n",
      "        [ 2.0433e+00],\n",
      "        [ 2.0083e+00],\n",
      "        [ 2.0166e+00],\n",
      "        [ 2.0150e+00],\n",
      "        [ 1.9982e+00],\n",
      "        [ 2.0551e+00],\n",
      "        [ 2.0451e+00],\n",
      "        [ 2.0017e+00],\n",
      "        [ 1.9633e+00],\n",
      "        [ 1.9882e+00],\n",
      "        [ 1.9879e+00],\n",
      "        [ 1.9571e+00],\n",
      "        [ 2.0042e+00],\n",
      "        [ 1.9992e+00],\n",
      "        [ 2.0113e+00],\n",
      "        [ 1.9861e+00],\n",
      "        [ 1.9969e+00],\n",
      "        [ 1.9776e+00],\n",
      "        [-7.2219e-03],\n",
      "        [-2.7363e-02],\n",
      "        [ 1.6200e-02],\n",
      "        [-1.2656e-02],\n",
      "        [-3.2145e-02],\n",
      "        [ 1.2234e-02],\n",
      "        [ 6.1783e-04],\n",
      "        [-1.0925e-02],\n",
      "        [ 1.7339e-02],\n",
      "        [-1.4584e-03],\n",
      "        [ 2.8750e-03],\n",
      "        [-2.5875e-04],\n",
      "        [ 2.3251e-02],\n",
      "        [ 4.4086e-03],\n",
      "        [-4.3658e-02],\n",
      "        [ 1.1940e-02],\n",
      "        [-3.6621e-02],\n",
      "        [-1.7383e-02],\n",
      "        [ 9.2726e-03],\n",
      "        [-3.2581e-02],\n",
      "        [-6.3301e-02],\n",
      "        [-4.8596e-02],\n",
      "        [ 3.6273e-02],\n",
      "        [-2.7613e-02],\n",
      "        [-4.1760e-03]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(v * w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3de0db53",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-Xu(v\\odot w)^T\\rVert_F^2$$\n",
    "where for any matrix $A$, \n",
    "#### $$\\lVert A\\rVert_F^2 = \\sum_{i,j}A_{i,j}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d499d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(p, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c67ed225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_2(u, v, w):\n",
    "    A = X - (X.double() @ u.double()).double() @ (v * w).T.double()\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ddb240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 1016096.311419646\n",
      "Epoch 1000: loss = 8257.576853699546\n",
      "Epoch 2000: loss = 7630.172244867054\n",
      "Epoch 3000: loss = 7318.756262134051\n",
      "Epoch 4000: loss = 7089.231844062579\n",
      "Epoch 5000: loss = 6820.800376898386\n",
      "Epoch 6000: loss = 6397.108471559741\n",
      "Epoch 7000: loss = 5727.698655353705\n",
      "Epoch 8000: loss = 4791.779049807653\n",
      "Epoch 9000: loss = 3646.3175619345366\n",
      "Epoch 10000: loss = 2497.3930464614114\n",
      "Epoch 11000: loss = 1637.9070427442666\n",
      "Epoch 12000: loss = 1119.58438770143\n",
      "Epoch 13000: loss = 805.0202745665249\n",
      "Epoch 14000: loss = 570.9062590060433\n",
      "Epoch 15000: loss = 379.31077816757085\n",
      "Epoch 16000: loss = 242.0017836530929\n",
      "Epoch 17000: loss = 168.38658016027344\n",
      "Epoch 18000: loss = 139.81037323392223\n",
      "Epoch 19000: loss = 129.19134256971634\n",
      "Epoch 20000: loss = 123.5860253951027\n",
      "Epoch 21000: loss = 119.4858670334865\n",
      "Epoch 22000: loss = 116.08519905550042\n",
      "Epoch 23000: loss = 113.14648291257757\n",
      "Epoch 24000: loss = 110.56196425983376\n",
      "Epoch 25000: loss = 108.25959437251247\n",
      "Epoch 26000: loss = 106.18980695705444\n",
      "Epoch 27000: loss = 104.31361731708685\n",
      "Epoch 28000: loss = 102.6020705271909\n",
      "Epoch 29000: loss = 101.03090721043688\n",
      "Epoch 30000: loss = 99.58282648478068\n",
      "Epoch 31000: loss = 98.23926412542993\n",
      "Epoch 32000: loss = 96.99096776109961\n",
      "Epoch 33000: loss = 95.82509892409928\n",
      "Epoch 34000: loss = 94.73240265283101\n",
      "Epoch 35000: loss = 93.70694629680585\n",
      "Epoch 36000: loss = 92.74050872770877\n",
      "Epoch 37000: loss = 91.82789505747115\n",
      "Epoch 38000: loss = 90.96615046344266\n",
      "Epoch 39000: loss = 90.14804709470982\n",
      "Epoch 40000: loss = 89.3710344747599\n",
      "Epoch 41000: loss = 88.6332270734298\n",
      "Epoch 42000: loss = 87.93014216792162\n",
      "Epoch 43000: loss = 87.25917265261951\n",
      "Epoch 44000: loss = 86.61814724386161\n",
      "Epoch 45000: loss = 86.00555357325652\n",
      "Epoch 46000: loss = 85.42049502237741\n",
      "Epoch 47000: loss = 84.85934354768597\n",
      "Epoch 48000: loss = 84.3196429076723\n",
      "Epoch 49000: loss = 83.80273502231736\n",
      "Epoch 50000: loss = 83.30606796331335\n",
      "Epoch 51000: loss = 82.82889410247012\n",
      "Epoch 52000: loss = 82.3690355270265\n",
      "Epoch 53000: loss = 81.92628151351116\n",
      "Epoch 54000: loss = 81.49873090662713\n",
      "Epoch 55000: loss = 81.08728178812848\n",
      "Epoch 56000: loss = 80.69093823956874\n",
      "Epoch 57000: loss = 80.30785873603784\n",
      "Epoch 58000: loss = 79.93720895839084\n",
      "Epoch 59000: loss = 79.57944304345892\n",
      "Epoch 60000: loss = 79.23253877406474\n",
      "Epoch 61000: loss = 78.89620788512676\n",
      "Epoch 62000: loss = 78.57150281622846\n",
      "Epoch 63000: loss = 78.25791750242806\n",
      "Epoch 64000: loss = 77.95304884691127\n",
      "Epoch 65000: loss = 77.65700467644487\n",
      "Epoch 66000: loss = 77.36992745252834\n",
      "Epoch 67000: loss = 77.09125531269078\n",
      "Epoch 68000: loss = 76.82030387762282\n",
      "Epoch 69000: loss = 76.55735493732764\n",
      "Epoch 70000: loss = 76.301969965658\n",
      "Epoch 71000: loss = 76.05344015889696\n",
      "Epoch 72000: loss = 75.8114105130334\n",
      "Epoch 73000: loss = 75.57643996922255\n",
      "Epoch 74000: loss = 75.34756756651213\n",
      "Epoch 75000: loss = 75.12441030164202\n",
      "Epoch 76000: loss = 74.90666163168588\n",
      "Epoch 77000: loss = 74.69519280105985\n",
      "Epoch 78000: loss = 74.48883914394128\n",
      "Epoch 79000: loss = 74.28752359356555\n",
      "Epoch 80000: loss = 74.09104593493609\n",
      "Epoch 81000: loss = 73.899774186801\n",
      "Epoch 82000: loss = 73.71348862818394\n",
      "Epoch 83000: loss = 73.53167834887195\n",
      "Epoch 84000: loss = 73.35382991677452\n",
      "Epoch 85000: loss = 73.17982950310565\n",
      "Epoch 86000: loss = 73.00954590754404\n",
      "Epoch 87000: loss = 72.84324543229937\n",
      "Epoch 88000: loss = 72.6810670051099\n",
      "Epoch 89000: loss = 72.52218962274253\n",
      "Epoch 90000: loss = 72.3667048642237\n",
      "Epoch 91000: loss = 72.21491928233758\n",
      "Epoch 92000: loss = 72.066439488544\n",
      "Epoch 93000: loss = 71.92116439687217\n",
      "Epoch 94000: loss = 71.77877841509685\n",
      "Epoch 95000: loss = 71.63941563617013\n",
      "Epoch 96000: loss = 71.5030335100287\n",
      "Epoch 97000: loss = 71.3694600543403\n",
      "Epoch 98000: loss = 71.23901086906756\n",
      "Epoch 99000: loss = 71.1109488994513\n",
      "Epoch 100000: loss = 70.98535742025794\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "step_size = 5e-7\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_2(u, v, w)\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "#         if (i == epochs - 1):\n",
    "#             print(u.grad)\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_2(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7243c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7077e-01],\n",
      "        [ 3.8000e-01],\n",
      "        [ 3.7584e-01],\n",
      "        [ 3.6176e-01],\n",
      "        [ 3.6826e-01],\n",
      "        [ 3.6338e-01],\n",
      "        [ 3.6840e-01],\n",
      "        [ 3.7576e-01],\n",
      "        [ 3.6944e-01],\n",
      "        [ 3.7080e-01],\n",
      "        [ 3.7024e-01],\n",
      "        [ 3.6751e-01],\n",
      "        [ 3.7808e-01],\n",
      "        [ 3.7552e-01],\n",
      "        [ 3.6837e-01],\n",
      "        [ 3.6106e-01],\n",
      "        [ 3.6548e-01],\n",
      "        [ 3.6508e-01],\n",
      "        [ 3.5957e-01],\n",
      "        [ 3.6817e-01],\n",
      "        [ 3.6797e-01],\n",
      "        [ 3.6966e-01],\n",
      "        [ 3.6529e-01],\n",
      "        [ 3.6703e-01],\n",
      "        [ 3.6402e-01],\n",
      "        [-1.2101e-03],\n",
      "        [-4.8834e-03],\n",
      "        [ 5.6760e-03],\n",
      "        [-2.3469e-03],\n",
      "        [-5.8679e-03],\n",
      "        [ 2.2008e-03],\n",
      "        [ 1.4549e-03],\n",
      "        [-2.1614e-03],\n",
      "        [ 3.2415e-03],\n",
      "        [-8.6835e-04],\n",
      "        [ 5.5093e-04],\n",
      "        [-2.9431e-05],\n",
      "        [ 4.4851e-03],\n",
      "        [ 7.9124e-04],\n",
      "        [-7.9547e-03],\n",
      "        [ 2.0991e-03],\n",
      "        [-6.8081e-03],\n",
      "        [-3.0611e-03],\n",
      "        [ 1.6274e-03],\n",
      "        [-6.0752e-03],\n",
      "        [-1.1831e-02],\n",
      "        [-9.1508e-03],\n",
      "        [ 6.7416e-03],\n",
      "        [-5.1772e-03],\n",
      "        [-8.2642e-04]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(v * w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39b4828f",
   "metadata": {},
   "source": [
    "## Method 3\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-u(v\\odot v - w\\odot w)^T\\rVert_F^2$$\n",
    "where for any matrix $A$, \n",
    "#### $$\\lVert A\\rVert_F^2 = \\sum_{i,j}A_{i,j}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc707f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(n, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "927688d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_3(u, v, w):\n",
    "    A = X - u @ (v * v - w * w).T\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9874a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 9350.400290968457\n",
      "Epoch 100: loss = 6019.834603736181\n",
      "Epoch 200: loss = 103.60049566826791\n",
      "Epoch 300: loss = 62.332700579023175\n",
      "Epoch 400: loss = 60.76330112634478\n",
      "Epoch 500: loss = 60.2217831291857\n",
      "Epoch 600: loss = 59.98226087118297\n",
      "Epoch 700: loss = 59.85953161774421\n",
      "Epoch 800: loss = 59.79038399869839\n",
      "Epoch 900: loss = 59.74867687697315\n",
      "Epoch 1000: loss = 59.722093423809696\n",
      "Epoch 1100: loss = 59.70430126518195\n",
      "Epoch 1200: loss = 59.69184482728345\n",
      "Epoch 1300: loss = 59.68275678141781\n",
      "Epoch 1400: loss = 59.67588164501595\n",
      "Epoch 1500: loss = 59.67051188076208\n",
      "Epoch 1600: loss = 59.66620563445094\n",
      "Epoch 1700: loss = 59.662676238132875\n",
      "Epoch 1800: loss = 59.65973043451327\n",
      "Epoch 1900: loss = 59.65723739487805\n",
      "Epoch 2000: loss = 59.65509876329735\n",
      "Epoch 2100: loss = 59.65324698214902\n",
      "Epoch 2200: loss = 59.651630065917644\n",
      "Epoch 2300: loss = 59.65020602321553\n",
      "Epoch 2400: loss = 59.648947557118014\n",
      "Epoch 2500: loss = 59.647824054482385\n",
      "Epoch 2600: loss = 59.64681877344373\n",
      "Epoch 2700: loss = 59.6459139372911\n",
      "Epoch 2800: loss = 59.64509777754016\n",
      "Epoch 2900: loss = 59.644355551751914\n",
      "Epoch 3000: loss = 59.64367822204634\n",
      "Epoch 3100: loss = 59.64305905903829\n",
      "Epoch 3200: loss = 59.64249017152344\n",
      "Epoch 3300: loss = 59.6419676518873\n",
      "Epoch 3400: loss = 59.64148174869695\n",
      "Epoch 3500: loss = 59.64103257632143\n",
      "Epoch 3600: loss = 59.640612058400635\n",
      "Epoch 3700: loss = 59.6402190222022\n",
      "Epoch 3800: loss = 59.639851076016406\n",
      "Epoch 3900: loss = 59.63950321603493\n",
      "Epoch 4000: loss = 59.63917334914596\n",
      "Epoch 4100: loss = 59.63886172224616\n",
      "Epoch 4200: loss = 59.63856234178482\n",
      "Epoch 4300: loss = 59.63827707004282\n",
      "Epoch 4400: loss = 59.63800227533923\n",
      "Epoch 4500: loss = 59.63773652483036\n",
      "Epoch 4600: loss = 59.63747698581627\n",
      "Epoch 4700: loss = 59.63722571516079\n",
      "Epoch 4800: loss = 59.63697832361258\n",
      "Epoch 4900: loss = 59.63673666045246\n",
      "Epoch 5000: loss = 59.636495483497676\n",
      "Epoch 5100: loss = 59.63625866423297\n",
      "Epoch 5200: loss = 59.6360216364378\n",
      "Epoch 5300: loss = 59.63578698096951\n",
      "Epoch 5400: loss = 59.63554966347503\n",
      "Epoch 5500: loss = 59.63530962465124\n",
      "Epoch 5600: loss = 59.63506832208976\n",
      "Epoch 5700: loss = 59.634825441033634\n",
      "Epoch 5800: loss = 59.63457808537205\n",
      "Epoch 5900: loss = 59.63432695827937\n",
      "Epoch 6000: loss = 59.63406998095624\n",
      "Epoch 6100: loss = 59.63380956484379\n",
      "Epoch 6200: loss = 59.63354150990067\n",
      "Epoch 6300: loss = 59.633268603478186\n",
      "Epoch 6400: loss = 59.63298729952588\n",
      "Epoch 6500: loss = 59.63269781414729\n",
      "Epoch 6600: loss = 59.63240594843327\n",
      "Epoch 6700: loss = 59.63210190720163\n",
      "Epoch 6800: loss = 59.631792376240234\n",
      "Epoch 6900: loss = 59.631474479478996\n",
      "Epoch 7000: loss = 59.63114861676256\n",
      "Epoch 7100: loss = 59.630815390917235\n",
      "Epoch 7200: loss = 59.63047492406197\n",
      "Epoch 7300: loss = 59.63012646513685\n",
      "Epoch 7400: loss = 59.62976874059607\n",
      "Epoch 7500: loss = 59.62940704888039\n",
      "Epoch 7600: loss = 59.62903751317815\n",
      "Epoch 7700: loss = 59.628659668301424\n",
      "Epoch 7800: loss = 59.62828020720958\n",
      "Epoch 7900: loss = 59.627895129963235\n",
      "Epoch 8000: loss = 59.62750340119825\n",
      "Epoch 8100: loss = 59.62710947601448\n",
      "Epoch 8200: loss = 59.62671244238612\n",
      "Epoch 8300: loss = 59.62631458942238\n",
      "Epoch 8400: loss = 59.625917090570184\n",
      "Epoch 8500: loss = 59.62551698689655\n",
      "Epoch 8600: loss = 59.625119839011816\n",
      "Epoch 8700: loss = 59.62472678932339\n",
      "Epoch 8800: loss = 59.62433135643435\n",
      "Epoch 8900: loss = 59.6239469731905\n",
      "Epoch 9000: loss = 59.62356543019058\n",
      "Epoch 9100: loss = 59.62319121836592\n",
      "Epoch 9200: loss = 59.62282180840191\n",
      "Epoch 9300: loss = 59.622464514321635\n",
      "Epoch 9400: loss = 59.62211209696245\n",
      "Epoch 9500: loss = 59.6217752164517\n",
      "Epoch 9600: loss = 59.62144613586157\n",
      "Epoch 9700: loss = 59.62112833887184\n",
      "Epoch 9800: loss = 59.620822774330755\n",
      "Epoch 9900: loss = 59.62052995447542\n",
      "Epoch 10000: loss = 59.62024891106489\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "step_size = 1e-4\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_3(u, v, w)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_3(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8338990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9115e+00],\n",
      "        [ 2.9849e+00],\n",
      "        [ 2.9510e+00],\n",
      "        [ 2.8403e+00],\n",
      "        [ 2.8949e+00],\n",
      "        [ 2.8536e+00],\n",
      "        [ 2.8983e+00],\n",
      "        [ 2.9521e+00],\n",
      "        [ 2.9015e+00],\n",
      "        [ 2.9135e+00],\n",
      "        [ 2.9113e+00],\n",
      "        [ 2.8870e+00],\n",
      "        [ 2.9692e+00],\n",
      "        [ 2.9548e+00],\n",
      "        [ 2.8921e+00],\n",
      "        [ 2.8365e+00],\n",
      "        [ 2.8725e+00],\n",
      "        [ 2.8721e+00],\n",
      "        [ 2.8275e+00],\n",
      "        [ 2.8956e+00],\n",
      "        [ 2.8884e+00],\n",
      "        [ 2.9059e+00],\n",
      "        [ 2.8695e+00],\n",
      "        [ 2.8851e+00],\n",
      "        [ 2.8573e+00],\n",
      "        [-1.0429e-02],\n",
      "        [-3.9532e-02],\n",
      "        [ 2.3401e-02],\n",
      "        [-1.8284e-02],\n",
      "        [-4.6444e-02],\n",
      "        [ 1.7671e-02],\n",
      "        [ 1.1991e-02],\n",
      "        [-1.5781e-02],\n",
      "        [ 1.4360e-02],\n",
      "        [-5.9769e-03],\n",
      "        [ 4.1511e-03],\n",
      "        [-3.7705e-04],\n",
      "        [ 3.3591e-02],\n",
      "        [ 6.3651e-03],\n",
      "        [-6.3082e-02],\n",
      "        [ 1.7245e-02],\n",
      "        [-5.2907e-02],\n",
      "        [-2.5119e-02],\n",
      "        [ 1.3395e-02],\n",
      "        [-4.7070e-02],\n",
      "        [-9.1453e-02],\n",
      "        [-7.0210e-02],\n",
      "        [ 5.2405e-02],\n",
      "        [-3.9896e-02],\n",
      "        [-6.0388e-03]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(v * v - w * w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "255360da",
   "metadata": {},
   "source": [
    "## Method 4\n",
    "We want to find $(u, v, w)$ such that \n",
    "#### $$(u, v, w)=\\underset{(u, v, w)}{\\text{argmin}}\\ \\lVert X-Xu(v\\odot v - w\\odot w)^T\\rVert_F^2$$\n",
    "where for any matrix $A$, \n",
    "#### $$\\lVert A\\rVert_F^2 = \\sum_{i,j}A_{i,j}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0e46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(p, 1, requires_grad=True)\n",
    "v = torch.randn(p, 1, requires_grad=True)\n",
    "w = torch.randn(p, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9618a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_4(u, v, w):\n",
    "    A = X - X.double() @ u.double() @ (v * v - w * w).T.double()\n",
    "    return torch.sum(A * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e879801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 750613.6295650415\n",
      "Epoch 100: loss = 15788.892943445073\n",
      "Epoch 200: loss = 13173.91828193986\n",
      "Epoch 300: loss = 11540.745423258704\n",
      "Epoch 400: loss = 10426.486059073091\n",
      "Epoch 500: loss = 9613.011791135992\n",
      "Epoch 600: loss = 8984.86655373474\n",
      "Epoch 700: loss = 8475.462751428351\n",
      "Epoch 800: loss = 8043.816956578219\n",
      "Epoch 900: loss = 7663.4739495748745\n",
      "Epoch 1000: loss = 7316.839626931993\n",
      "Epoch 1100: loss = 6992.101207497644\n",
      "Epoch 1200: loss = 6681.409797841604\n",
      "Epoch 1300: loss = 6379.716729325701\n",
      "Epoch 1400: loss = 6083.95043313322\n",
      "Epoch 1500: loss = 5792.387010233472\n",
      "Epoch 1600: loss = 5504.199961844033\n",
      "Epoch 1700: loss = 5219.1467436587145\n",
      "Epoch 1800: loss = 4937.388735037206\n",
      "Epoch 1900: loss = 4659.384801606531\n",
      "Epoch 2000: loss = 4385.8384467317865\n",
      "Epoch 2100: loss = 4117.635441550416\n",
      "Epoch 2200: loss = 3855.797498879185\n",
      "Epoch 2300: loss = 3601.4099650600597\n",
      "Epoch 2400: loss = 3355.5640539977603\n",
      "Epoch 2500: loss = 3119.2906595674604\n",
      "Epoch 2600: loss = 2893.513006657904\n",
      "Epoch 2700: loss = 2679.014057184747\n",
      "Epoch 2800: loss = 2476.4027894077353\n",
      "Epoch 2900: loss = 2286.0930949479803\n",
      "Epoch 3000: loss = 2108.2886220159844\n",
      "Epoch 3100: loss = 1942.9831566304247\n",
      "Epoch 3200: loss = 1789.9679768543338\n",
      "Epoch 3300: loss = 1648.8551435019494\n",
      "Epoch 3400: loss = 1519.1125078596538\n",
      "Epoch 3500: loss = 1400.1145638715548\n",
      "Epoch 3600: loss = 1291.198065857355\n",
      "Epoch 3700: loss = 1191.7183836247882\n",
      "Epoch 3800: loss = 1101.099124260372\n",
      "Epoch 3900: loss = 1018.8602596638746\n",
      "Epoch 4000: loss = 944.6157876992402\n",
      "Epoch 4100: loss = 878.0443840696904\n",
      "Epoch 4200: loss = 818.8384554747299\n",
      "Epoch 4300: loss = 766.6493212917705\n",
      "Epoch 4400: loss = 721.0425106535843\n",
      "Epoch 4500: loss = 681.4739162537\n",
      "Epoch 4600: loss = 647.2950822204778\n",
      "Epoch 4700: loss = 617.7756573643426\n",
      "Epoch 4800: loss = 592.1426358266779\n",
      "Epoch 4900: loss = 569.6190232278547\n",
      "Epoch 5000: loss = 549.4604145256621\n",
      "Epoch 5100: loss = 530.9800490841328\n",
      "Epoch 5200: loss = 513.5653354405612\n",
      "Epoch 5300: loss = 496.68566264967023\n",
      "Epoch 5400: loss = 479.89579052541166\n",
      "Epoch 5500: loss = 462.83853261214017\n",
      "Epoch 5600: loss = 445.2462265074771\n",
      "Epoch 5700: loss = 426.9475720849475\n",
      "Epoch 5800: loss = 407.87457171146855\n",
      "Epoch 5900: loss = 388.07175848833884\n",
      "Epoch 6000: loss = 367.69846564059094\n",
      "Epoch 6100: loss = 347.02833954905174\n",
      "Epoch 6200: loss = 326.43165372361904\n",
      "Epoch 6300: loss = 306.34373959226645\n",
      "Epoch 6400: loss = 287.2192377014002\n",
      "Epoch 6500: loss = 269.47632866420315\n",
      "Epoch 6600: loss = 253.44504002897406\n",
      "Epoch 6700: loss = 239.32907444037525\n",
      "Epoch 6800: loss = 227.19167459932507\n",
      "Epoch 6900: loss = 216.96547386495607\n",
      "Epoch 7000: loss = 208.4829558759456\n",
      "Epoch 7100: loss = 201.51404631655097\n",
      "Epoch 7200: loss = 195.80490939747938\n",
      "Epoch 7300: loss = 191.10809028635546\n",
      "Epoch 7400: loss = 187.20150765401604\n",
      "Epoch 7500: loss = 183.898414086993\n",
      "Epoch 7600: loss = 181.04908019294797\n",
      "Epoch 7700: loss = 178.53849566852136\n",
      "Epoch 7800: loss = 176.27989754169982\n",
      "Epoch 7900: loss = 174.21007705275198\n",
      "Epoch 8000: loss = 172.28374454980252\n",
      "Epoch 8100: loss = 170.46860573511188\n",
      "Epoch 8200: loss = 168.74180915884787\n",
      "Epoch 8300: loss = 167.0873676289571\n",
      "Epoch 8400: loss = 165.49410531421336\n",
      "Epoch 8500: loss = 163.95369063567625\n",
      "Epoch 8600: loss = 162.46051857055625\n",
      "Epoch 8700: loss = 161.00981753111924\n",
      "Epoch 8800: loss = 159.59876646858729\n",
      "Epoch 8900: loss = 158.22429578514706\n",
      "Epoch 9000: loss = 156.8844232311421\n",
      "Epoch 9100: loss = 155.57744496738064\n",
      "Epoch 9200: loss = 154.30181117610223\n",
      "Epoch 9300: loss = 153.05605964947318\n",
      "Epoch 9400: loss = 151.83926391082497\n",
      "Epoch 9500: loss = 150.64990936706624\n",
      "Epoch 9600: loss = 149.48737774541183\n",
      "Epoch 9700: loss = 148.35021546107234\n",
      "Epoch 9800: loss = 147.23791134478222\n",
      "Epoch 9900: loss = 146.14959747305315\n",
      "Epoch 10000: loss = 145.08449770638725\n",
      "Epoch 10100: loss = 144.04176926869567\n",
      "Epoch 10200: loss = 143.02066291615995\n",
      "Epoch 10300: loss = 142.02070812006963\n",
      "Epoch 10400: loss = 141.04102942857762\n",
      "Epoch 10500: loss = 140.0811129433958\n",
      "Epoch 10600: loss = 139.1404205038016\n",
      "Epoch 10700: loss = 138.21813530623533\n",
      "Epoch 10800: loss = 137.31416863620626\n",
      "Epoch 10900: loss = 136.42762387841321\n",
      "Epoch 11000: loss = 135.5581332207518\n",
      "Epoch 11100: loss = 134.70533308157826\n",
      "Epoch 11200: loss = 133.8686244085936\n",
      "Epoch 11300: loss = 133.04768208527437\n",
      "Epoch 11400: loss = 132.24218777382345\n",
      "Epoch 11500: loss = 131.451459436003\n",
      "Epoch 11600: loss = 130.67519984936627\n",
      "Epoch 11700: loss = 129.91315144246354\n",
      "Epoch 11800: loss = 129.16491854509547\n",
      "Epoch 11900: loss = 128.4299980026147\n",
      "Epoch 12000: loss = 127.70826954860267\n",
      "Epoch 12100: loss = 126.99928066000538\n",
      "Epoch 12200: loss = 126.30271927632789\n",
      "Epoch 12300: loss = 125.61840485364671\n",
      "Epoch 12400: loss = 124.94598775338964\n",
      "Epoch 12500: loss = 124.28523029707736\n",
      "Epoch 12600: loss = 123.63575317667622\n",
      "Epoch 12700: loss = 122.99727680407312\n",
      "Epoch 12800: loss = 122.36960420616595\n",
      "Epoch 12900: loss = 121.75240851220325\n",
      "Epoch 13000: loss = 121.14558147844173\n",
      "Epoch 13100: loss = 120.5489421938606\n",
      "Epoch 13200: loss = 119.96204135005905\n",
      "Epoch 13300: loss = 119.38465177218325\n",
      "Epoch 13400: loss = 118.8168028530253\n",
      "Epoch 13500: loss = 118.25810724576013\n",
      "Epoch 13600: loss = 117.70847550336077\n",
      "Epoch 13700: loss = 117.16750171931993\n",
      "Epoch 13800: loss = 116.63520860952825\n",
      "Epoch 13900: loss = 116.1114251710082\n",
      "Epoch 14000: loss = 115.59576203103795\n",
      "Epoch 14100: loss = 115.08821617463542\n",
      "Epoch 14200: loss = 114.58861026045324\n",
      "Epoch 14300: loss = 114.09655700437453\n",
      "Epoch 14400: loss = 113.6120590989323\n",
      "Epoch 14500: loss = 113.13503407168277\n",
      "Epoch 14600: loss = 112.66524784324248\n",
      "Epoch 14700: loss = 112.20260824344322\n",
      "Epoch 14800: loss = 111.74691565978841\n",
      "Epoch 14900: loss = 111.29789233553042\n",
      "Epoch 15000: loss = 110.8555428620928\n",
      "Epoch 15100: loss = 110.4196691322604\n",
      "Epoch 15200: loss = 109.99032211678866\n",
      "Epoch 15300: loss = 109.56711488699219\n",
      "Epoch 15400: loss = 109.15007937017864\n",
      "Epoch 15500: loss = 108.73915847424416\n",
      "Epoch 15600: loss = 108.3340202466128\n",
      "Epoch 15700: loss = 107.93467542200733\n",
      "Epoch 15800: loss = 107.54107345557978\n",
      "Epoch 15900: loss = 107.15308578508818\n",
      "Epoch 16000: loss = 106.7704162882325\n",
      "Epoch 16100: loss = 106.39320212312963\n",
      "Epoch 16200: loss = 106.02115988342034\n",
      "Epoch 16300: loss = 105.65433215097593\n",
      "Epoch 16400: loss = 105.29246751519182\n",
      "Epoch 16500: loss = 104.93565059639067\n",
      "Epoch 16600: loss = 104.58368119619475\n",
      "Epoch 16700: loss = 104.23643402829528\n",
      "Epoch 16800: loss = 103.89374396600635\n",
      "Epoch 16900: loss = 103.55569225951184\n",
      "Epoch 17000: loss = 103.22209227654191\n",
      "Epoch 17100: loss = 102.89303328595938\n",
      "Epoch 17200: loss = 102.56818006574835\n",
      "Epoch 17300: loss = 102.2475883336621\n",
      "Epoch 17400: loss = 101.93118739547143\n",
      "Epoch 17500: loss = 101.61890896909942\n",
      "Epoch 17600: loss = 101.31060087717353\n",
      "Epoch 17700: loss = 101.00632513649165\n",
      "Epoch 17800: loss = 100.70595805633843\n",
      "Epoch 17900: loss = 100.40941239851865\n",
      "Epoch 18000: loss = 100.11654713246497\n",
      "Epoch 18100: loss = 99.82733529902328\n",
      "Epoch 18200: loss = 99.54181085362734\n",
      "Epoch 18300: loss = 99.25984549068843\n",
      "Epoch 18400: loss = 98.98131048258433\n",
      "Epoch 18500: loss = 98.70628977104136\n",
      "Epoch 18600: loss = 98.43459104662062\n",
      "Epoch 18700: loss = 98.16631464807512\n",
      "Epoch 18800: loss = 97.90119869714404\n",
      "Epoch 18900: loss = 97.63928588070863\n",
      "Epoch 19000: loss = 97.38049434697784\n",
      "Epoch 19100: loss = 97.12482755006242\n",
      "Epoch 19200: loss = 96.87214144172304\n",
      "Epoch 19300: loss = 96.62260783174975\n",
      "Epoch 19400: loss = 96.37597596000928\n",
      "Epoch 19500: loss = 96.13231702614598\n",
      "Epoch 19600: loss = 95.89144219230326\n",
      "Epoch 19700: loss = 95.65329739426664\n",
      "Epoch 19800: loss = 95.41790307354653\n",
      "Epoch 19900: loss = 95.18521766712797\n",
      "Epoch 20000: loss = 94.9552854205809\n",
      "Epoch 20100: loss = 94.72795330551102\n",
      "Epoch 20200: loss = 94.50306641693427\n",
      "Epoch 20300: loss = 94.28084186689097\n",
      "Epoch 20400: loss = 94.06113332184114\n",
      "Epoch 20500: loss = 93.84385370835733\n",
      "Epoch 20600: loss = 93.62909819831354\n",
      "Epoch 20700: loss = 93.41659213781769\n",
      "Epoch 20800: loss = 93.20637003444999\n",
      "Epoch 20900: loss = 92.99858179520744\n",
      "Epoch 21000: loss = 92.79308182987363\n",
      "Epoch 21100: loss = 92.5898111699783\n",
      "Epoch 21200: loss = 92.38874132786387\n",
      "Epoch 21300: loss = 92.18989068542697\n",
      "Epoch 21400: loss = 91.99304471348213\n",
      "Epoch 21500: loss = 91.79835193768145\n",
      "Epoch 21600: loss = 91.60574732453424\n",
      "Epoch 21700: loss = 91.41525343016974\n",
      "Epoch 21800: loss = 91.22669046974661\n",
      "Epoch 21900: loss = 91.04032176344822\n",
      "Epoch 22000: loss = 90.85575572901942\n",
      "Epoch 22100: loss = 90.67301552855149\n",
      "Epoch 22200: loss = 90.49226863672884\n",
      "Epoch 22300: loss = 90.31343896437436\n",
      "Epoch 22400: loss = 90.13637396327003\n",
      "Epoch 22500: loss = 89.96127769590612\n",
      "Epoch 22600: loss = 89.78790008594699\n",
      "Epoch 22700: loss = 89.61631350873915\n",
      "Epoch 22800: loss = 89.44633707842146\n",
      "Epoch 22900: loss = 89.27814737749263\n",
      "Epoch 23000: loss = 89.1117057698749\n",
      "Epoch 23100: loss = 88.94693451027788\n",
      "Epoch 23200: loss = 88.78375203816192\n",
      "Epoch 23300: loss = 88.62229574267505\n",
      "Epoch 23400: loss = 88.46237737644334\n",
      "Epoch 23500: loss = 88.30391941801739\n",
      "Epoch 23600: loss = 88.14699277517595\n",
      "Epoch 23700: loss = 87.99180382458493\n",
      "Epoch 23800: loss = 87.83793562582855\n",
      "Epoch 23900: loss = 87.68562749579928\n",
      "Epoch 24000: loss = 87.53476909451298\n",
      "Epoch 24100: loss = 87.38549699622706\n",
      "Epoch 24200: loss = 87.23763268287905\n",
      "Epoch 24300: loss = 87.09111907371778\n",
      "Epoch 24400: loss = 86.9459340228357\n",
      "Epoch 24500: loss = 86.80217689207112\n",
      "Epoch 24600: loss = 86.65986269432939\n",
      "Epoch 24700: loss = 86.51872265044081\n",
      "Epoch 24800: loss = 86.37881624463992\n",
      "Epoch 24900: loss = 86.24048836009474\n",
      "Epoch 25000: loss = 86.10331423192666\n",
      "Epoch 25100: loss = 85.96733961631777\n",
      "Epoch 25200: loss = 85.83259819734158\n",
      "Epoch 25300: loss = 85.69909661457743\n",
      "Epoch 25400: loss = 85.5669509029378\n",
      "Epoch 25500: loss = 85.43604698325171\n",
      "Epoch 25600: loss = 85.30636187524874\n",
      "Epoch 25700: loss = 85.17784633650878\n",
      "Epoch 25800: loss = 85.05053774467456\n",
      "Epoch 25900: loss = 84.92439938883491\n",
      "Epoch 26000: loss = 84.79935038126963\n",
      "Epoch 26100: loss = 84.67537267650982\n",
      "Epoch 26200: loss = 84.55243236447856\n",
      "Epoch 26300: loss = 84.43072344344193\n",
      "Epoch 26400: loss = 84.31007211563757\n",
      "Epoch 26500: loss = 84.19041958571324\n",
      "Epoch 26600: loss = 84.07178977265414\n",
      "Epoch 26700: loss = 83.95414845217216\n",
      "Epoch 26800: loss = 83.8375700868078\n",
      "Epoch 26900: loss = 83.7220765033882\n",
      "Epoch 27000: loss = 83.60754824098495\n",
      "Epoch 27100: loss = 83.49390427030744\n",
      "Epoch 27200: loss = 83.38132648635097\n",
      "Epoch 27300: loss = 83.26985224623745\n",
      "Epoch 27400: loss = 83.15925602673914\n",
      "Epoch 27500: loss = 83.04965265116306\n",
      "Epoch 27600: loss = 82.94086986794\n",
      "Epoch 27700: loss = 82.8328818749676\n",
      "Epoch 27800: loss = 82.72599913588613\n",
      "Epoch 27900: loss = 82.62005260704962\n",
      "Epoch 28000: loss = 82.514840127182\n",
      "Epoch 28100: loss = 82.41051901631052\n",
      "Epoch 28200: loss = 82.30707255322955\n",
      "Epoch 28300: loss = 82.20445876752373\n",
      "Epoch 28400: loss = 82.1027986384403\n",
      "Epoch 28500: loss = 82.00192816337754\n",
      "Epoch 28600: loss = 81.901771745439\n",
      "Epoch 28700: loss = 81.80253657264961\n",
      "Epoch 28800: loss = 81.70413260368217\n",
      "Epoch 28900: loss = 81.60651687792524\n",
      "Epoch 29000: loss = 81.50965786173091\n",
      "Epoch 29100: loss = 81.41364498132032\n",
      "Epoch 29200: loss = 81.31846275775226\n",
      "Epoch 29300: loss = 81.2239738326729\n",
      "Epoch 29400: loss = 81.13019913572087\n",
      "Epoch 29500: loss = 81.03715918478534\n",
      "Epoch 29600: loss = 80.94497656870867\n",
      "Epoch 29700: loss = 80.85354367329928\n",
      "Epoch 29800: loss = 80.76271684884804\n",
      "Epoch 29900: loss = 80.67247365070526\n",
      "Epoch 30000: loss = 80.58297642914103\n",
      "Epoch 30100: loss = 80.49428609824147\n",
      "Epoch 30200: loss = 80.40636855804122\n",
      "Epoch 30300: loss = 80.31904279133269\n",
      "Epoch 30400: loss = 80.2324184687649\n",
      "Epoch 30500: loss = 80.1464540163176\n",
      "Epoch 30600: loss = 80.06110235539754\n",
      "Epoch 30700: loss = 79.97643251752842\n",
      "Epoch 30800: loss = 79.89256782971414\n",
      "Epoch 30900: loss = 79.80923257321135\n",
      "Epoch 31000: loss = 79.72649177554013\n",
      "Epoch 31100: loss = 79.64441376861792\n",
      "Epoch 31200: loss = 79.56296152345328\n",
      "Epoch 31300: loss = 79.48201029428361\n",
      "Epoch 31400: loss = 79.40161916327229\n",
      "Epoch 31500: loss = 79.3219573622966\n",
      "Epoch 31600: loss = 79.24282533122177\n",
      "Epoch 31700: loss = 79.16428341243216\n",
      "Epoch 31800: loss = 79.08628531550026\n",
      "Epoch 31900: loss = 79.00898956180936\n",
      "Epoch 32000: loss = 78.9321568585601\n",
      "Epoch 32100: loss = 78.85587683356958\n",
      "Epoch 32200: loss = 78.78023566008422\n",
      "Epoch 32300: loss = 78.70526316035634\n",
      "Epoch 32400: loss = 78.63072016660217\n",
      "Epoch 32500: loss = 78.55664231022158\n",
      "Epoch 32600: loss = 78.48305242120682\n",
      "Epoch 32700: loss = 78.41010949782594\n",
      "Epoch 32800: loss = 78.3376275178447\n",
      "Epoch 32900: loss = 78.2657347988201\n",
      "Epoch 33000: loss = 78.19427697188671\n",
      "Epoch 33100: loss = 78.12342891797145\n",
      "Epoch 33200: loss = 78.0530406278477\n",
      "Epoch 33300: loss = 77.98308585492009\n",
      "Epoch 33400: loss = 77.91358749048331\n",
      "Epoch 33500: loss = 77.84459274956183\n",
      "Epoch 33600: loss = 77.77624418118589\n",
      "Epoch 33700: loss = 77.70840676596818\n",
      "Epoch 33800: loss = 77.64098012190831\n",
      "Epoch 33900: loss = 77.57401762033857\n",
      "Epoch 34000: loss = 77.50753359435753\n",
      "Epoch 34100: loss = 77.44144303409057\n",
      "Epoch 34200: loss = 77.37573044356219\n",
      "Epoch 34300: loss = 77.3104480091624\n",
      "Epoch 34400: loss = 77.24578776357664\n",
      "Epoch 34500: loss = 77.18163086032735\n",
      "Epoch 34600: loss = 77.11782117911392\n",
      "Epoch 34700: loss = 77.05442386447093\n",
      "Epoch 34800: loss = 76.99140707854588\n",
      "Epoch 34900: loss = 76.9288684337826\n",
      "Epoch 35000: loss = 76.86666955994096\n",
      "Epoch 35100: loss = 76.80481388582626\n",
      "Epoch 35200: loss = 76.74335562051526\n",
      "Epoch 35300: loss = 76.68249814472004\n",
      "Epoch 35400: loss = 76.62205624242912\n",
      "Epoch 35500: loss = 76.56194591354071\n",
      "Epoch 35600: loss = 76.50224669904765\n",
      "Epoch 35700: loss = 76.44291829113497\n",
      "Epoch 35800: loss = 76.38400973421834\n",
      "Epoch 35900: loss = 76.32552203906958\n",
      "Epoch 36000: loss = 76.26743526097582\n",
      "Epoch 36100: loss = 76.2097354610913\n",
      "Epoch 36200: loss = 76.1523681180565\n",
      "Epoch 36300: loss = 76.0953833840666\n",
      "Epoch 36400: loss = 76.03873733920358\n",
      "Epoch 36500: loss = 75.98249512835072\n",
      "Epoch 36600: loss = 75.92661868008551\n",
      "Epoch 36700: loss = 75.87106480407854\n",
      "Epoch 36800: loss = 75.8158066432266\n",
      "Epoch 36900: loss = 75.76090864500537\n",
      "Epoch 37000: loss = 75.70632698537445\n",
      "Epoch 37100: loss = 75.65220061641668\n",
      "Epoch 37200: loss = 75.59841808992374\n",
      "Epoch 37300: loss = 75.54496408693154\n",
      "Epoch 37400: loss = 75.49184380785695\n",
      "Epoch 37500: loss = 75.4390108304489\n",
      "Epoch 37600: loss = 75.38647983941235\n",
      "Epoch 37700: loss = 75.3343290653326\n",
      "Epoch 37800: loss = 75.28251153620765\n",
      "Epoch 37900: loss = 75.23101922807183\n",
      "Epoch 38000: loss = 75.1798950928377\n",
      "Epoch 38100: loss = 75.12906125974061\n",
      "Epoch 38200: loss = 75.07848873554873\n",
      "Epoch 38300: loss = 75.02824551325\n",
      "Epoch 38400: loss = 74.97835759361763\n",
      "Epoch 38500: loss = 74.92882250749616\n",
      "Epoch 38600: loss = 74.87957341502803\n",
      "Epoch 38700: loss = 74.83061914050461\n",
      "Epoch 38800: loss = 74.78188651206327\n",
      "Epoch 38900: loss = 74.73338906340021\n",
      "Epoch 39000: loss = 74.68525801308071\n",
      "Epoch 39100: loss = 74.63751565325785\n",
      "Epoch 39200: loss = 74.59007575958672\n",
      "Epoch 39300: loss = 74.54292716033247\n",
      "Epoch 39400: loss = 74.49601662297762\n",
      "Epoch 39500: loss = 74.44933389922906\n",
      "Epoch 39600: loss = 74.40292529089007\n",
      "Epoch 39700: loss = 74.3567759376487\n",
      "Epoch 39800: loss = 74.31093894693615\n",
      "Epoch 39900: loss = 74.26533096591734\n",
      "Epoch 40000: loss = 74.21999687161293\n",
      "Epoch 40100: loss = 74.17494693073492\n",
      "Epoch 40200: loss = 74.13025429642323\n",
      "Epoch 40300: loss = 74.08584582028152\n",
      "Epoch 40400: loss = 74.0416966268885\n",
      "Epoch 40500: loss = 73.99774349088284\n",
      "Epoch 40600: loss = 73.95398434176175\n",
      "Epoch 40700: loss = 73.91047032650462\n",
      "Epoch 40800: loss = 73.867167060121\n",
      "Epoch 40900: loss = 73.82414319782305\n",
      "Epoch 41000: loss = 73.78137814634078\n",
      "Epoch 41100: loss = 73.73883267879444\n",
      "Epoch 41200: loss = 73.69654114516146\n",
      "Epoch 41300: loss = 73.65454742530784\n",
      "Epoch 41400: loss = 73.61276065323798\n",
      "Epoch 41500: loss = 73.57116430454286\n",
      "Epoch 41600: loss = 73.5298101700104\n",
      "Epoch 41700: loss = 73.48867391478271\n",
      "Epoch 41800: loss = 73.44774103844782\n",
      "Epoch 41900: loss = 73.40704990579539\n",
      "Epoch 42000: loss = 73.36659098226852\n",
      "Epoch 42100: loss = 73.32637116927584\n",
      "Epoch 42200: loss = 73.28637464227437\n",
      "Epoch 42300: loss = 73.24658792589237\n",
      "Epoch 42400: loss = 73.20711025761298\n",
      "Epoch 42500: loss = 73.167894812514\n",
      "Epoch 42600: loss = 73.12886958118682\n",
      "Epoch 42700: loss = 73.09004906724184\n",
      "Epoch 42800: loss = 73.05144660924888\n",
      "Epoch 42900: loss = 73.01301505876062\n",
      "Epoch 43000: loss = 72.97480024388202\n",
      "Epoch 43100: loss = 72.93681912484857\n",
      "Epoch 43200: loss = 72.89905819157863\n",
      "Epoch 43300: loss = 72.86145876611681\n",
      "Epoch 43400: loss = 72.82405280033178\n",
      "Epoch 43500: loss = 72.78684189995174\n",
      "Epoch 43600: loss = 72.74981467414983\n",
      "Epoch 43700: loss = 72.71302786104161\n",
      "Epoch 43800: loss = 72.67644479127553\n",
      "Epoch 43900: loss = 72.6400482544673\n",
      "Epoch 44000: loss = 72.6038660277928\n",
      "Epoch 44100: loss = 72.5678826361792\n",
      "Epoch 44200: loss = 72.5320793460562\n",
      "Epoch 44300: loss = 72.49645631585912\n",
      "Epoch 44400: loss = 72.46103065279866\n",
      "Epoch 44500: loss = 72.42579641947637\n",
      "Epoch 44600: loss = 72.39074249154987\n",
      "Epoch 44700: loss = 72.35586879029113\n",
      "Epoch 44800: loss = 72.32116067406056\n",
      "Epoch 44900: loss = 72.28665183965418\n",
      "Epoch 45000: loss = 72.25224906822422\n",
      "Epoch 45100: loss = 72.2180889662261\n",
      "Epoch 45200: loss = 72.1840866319659\n",
      "Epoch 45300: loss = 72.1502709401434\n",
      "Epoch 45400: loss = 72.11664465048128\n",
      "Epoch 45500: loss = 72.08321160283586\n",
      "Epoch 45600: loss = 72.04995964979571\n",
      "Epoch 45700: loss = 72.01683633043179\n",
      "Epoch 45800: loss = 71.98385971274259\n",
      "Epoch 45900: loss = 71.95105972386096\n",
      "Epoch 46000: loss = 71.9184175427577\n",
      "Epoch 46100: loss = 71.88592904498275\n",
      "Epoch 46200: loss = 71.85359732095544\n",
      "Epoch 46300: loss = 71.8214586642857\n",
      "Epoch 46400: loss = 71.78947038149452\n",
      "Epoch 46500: loss = 71.75770318267804\n",
      "Epoch 46600: loss = 71.7261122643244\n",
      "Epoch 46700: loss = 71.69467849718768\n",
      "Epoch 46800: loss = 71.66340757501081\n",
      "Epoch 46900: loss = 71.63229160457222\n",
      "Epoch 47000: loss = 71.60128617623212\n",
      "Epoch 47100: loss = 71.57043707448432\n",
      "Epoch 47200: loss = 71.53976352741238\n",
      "Epoch 47300: loss = 71.50922749589307\n",
      "Epoch 47400: loss = 71.47881157325045\n",
      "Epoch 47500: loss = 71.4485315871016\n",
      "Epoch 47600: loss = 71.41837313401261\n",
      "Epoch 47700: loss = 71.38834965336419\n",
      "Epoch 47800: loss = 71.3584888119553\n",
      "Epoch 47900: loss = 71.32876231443917\n",
      "Epoch 48000: loss = 71.29918474463864\n",
      "Epoch 48100: loss = 71.26978818798818\n",
      "Epoch 48200: loss = 71.24053933385612\n",
      "Epoch 48300: loss = 71.2114649325668\n",
      "Epoch 48400: loss = 71.18251996939121\n",
      "Epoch 48500: loss = 71.15369395691926\n",
      "Epoch 48600: loss = 71.12499448870544\n",
      "Epoch 48700: loss = 71.09643458537593\n",
      "Epoch 48800: loss = 71.0680004965786\n",
      "Epoch 48900: loss = 71.03968541766349\n",
      "Epoch 49000: loss = 71.0115031306029\n",
      "Epoch 49100: loss = 70.98346422890171\n",
      "Epoch 49200: loss = 70.95555020182208\n",
      "Epoch 49300: loss = 70.92777911486414\n",
      "Epoch 49400: loss = 70.90013461485869\n",
      "Epoch 49500: loss = 70.87262629871066\n",
      "Epoch 49600: loss = 70.84528641395806\n",
      "Epoch 49700: loss = 70.81813610783108\n",
      "Epoch 49800: loss = 70.7911205135174\n",
      "Epoch 49900: loss = 70.76421038966525\n",
      "Epoch 50000: loss = 70.73740235656537\n",
      "Epoch 50100: loss = 70.71071194860656\n",
      "Epoch 50200: loss = 70.68414628392523\n",
      "Epoch 50300: loss = 70.6576958993711\n",
      "Epoch 50400: loss = 70.63136555021418\n",
      "Epoch 50500: loss = 70.60516958464274\n",
      "Epoch 50600: loss = 70.57906798164014\n",
      "Epoch 50700: loss = 70.55307681435991\n",
      "Epoch 50800: loss = 70.52721459067763\n",
      "Epoch 50900: loss = 70.50147771164893\n",
      "Epoch 51000: loss = 70.47583828923153\n",
      "Epoch 51100: loss = 70.45029455934481\n",
      "Epoch 51200: loss = 70.42484556526192\n",
      "Epoch 51300: loss = 70.39952756818721\n",
      "Epoch 51400: loss = 70.37438113066504\n",
      "Epoch 51500: loss = 70.34939532000652\n",
      "Epoch 51600: loss = 70.3244768647071\n",
      "Epoch 51700: loss = 70.29964718142509\n",
      "Epoch 51800: loss = 70.27495937895688\n",
      "Epoch 51900: loss = 70.25038287418792\n",
      "Epoch 52000: loss = 70.22590576043866\n",
      "Epoch 52100: loss = 70.20152286276911\n",
      "Epoch 52200: loss = 70.17726037825139\n",
      "Epoch 52300: loss = 70.15311914440804\n",
      "Epoch 52400: loss = 70.12908154977445\n",
      "Epoch 52500: loss = 70.10514698571566\n",
      "Epoch 52600: loss = 70.0813148028388\n",
      "Epoch 52700: loss = 70.05757552114643\n",
      "Epoch 52800: loss = 70.03392275250187\n",
      "Epoch 52900: loss = 70.0103718136296\n",
      "Epoch 53000: loss = 69.98692021061672\n",
      "Epoch 53100: loss = 69.96354231033482\n",
      "Epoch 53200: loss = 69.94024634460658\n",
      "Epoch 53300: loss = 69.91709494377689\n",
      "Epoch 53400: loss = 69.89409035709082\n",
      "Epoch 53500: loss = 69.871186112827\n",
      "Epoch 53600: loss = 69.84836445582496\n",
      "Epoch 53700: loss = 69.82562725149111\n",
      "Epoch 53800: loss = 69.80301488021044\n",
      "Epoch 53900: loss = 69.78053460894456\n",
      "Epoch 54000: loss = 69.7581731428426\n",
      "Epoch 54100: loss = 69.73589230877802\n",
      "Epoch 54200: loss = 69.71370432960666\n",
      "Epoch 54300: loss = 69.69158959654632\n",
      "Epoch 54400: loss = 69.66955924040633\n",
      "Epoch 54500: loss = 69.64760251445205\n",
      "Epoch 54600: loss = 69.62574262775696\n",
      "Epoch 54700: loss = 69.60399093978519\n",
      "Epoch 54800: loss = 69.58229018143264\n",
      "Epoch 54900: loss = 69.56064325641464\n",
      "Epoch 55000: loss = 69.53908426562391\n",
      "Epoch 55100: loss = 69.51760792957514\n",
      "Epoch 55200: loss = 69.4962149242092\n",
      "Epoch 55300: loss = 69.47489751456473\n",
      "Epoch 55400: loss = 69.4537760782793\n",
      "Epoch 55500: loss = 69.43274474598199\n",
      "Epoch 55600: loss = 69.41177658336211\n",
      "Epoch 55700: loss = 69.39087035817494\n",
      "Epoch 55800: loss = 69.37008481036895\n",
      "Epoch 55900: loss = 69.34940353749624\n",
      "Epoch 56000: loss = 69.32880169172023\n",
      "Epoch 56100: loss = 69.30827848857717\n",
      "Epoch 56200: loss = 69.2878389966602\n",
      "Epoch 56300: loss = 69.26748062112182\n",
      "Epoch 56400: loss = 69.24718848696673\n",
      "Epoch 56500: loss = 69.22696263494637\n",
      "Epoch 56600: loss = 69.20683635283591\n",
      "Epoch 56700: loss = 69.18681034723042\n",
      "Epoch 56800: loss = 69.16685073828404\n",
      "Epoch 56900: loss = 69.14698430114487\n",
      "Epoch 57000: loss = 69.12718769384145\n",
      "Epoch 57100: loss = 69.10745050927298\n",
      "Epoch 57200: loss = 69.08778916633943\n",
      "Epoch 57300: loss = 69.06818521739663\n",
      "Epoch 57400: loss = 69.04865579615495\n",
      "Epoch 57500: loss = 69.02928100798535\n",
      "Epoch 57600: loss = 69.0099719511284\n",
      "Epoch 57700: loss = 68.99074737569653\n",
      "Epoch 57800: loss = 68.97158185445613\n",
      "Epoch 57900: loss = 68.9524894680555\n",
      "Epoch 58000: loss = 68.9334769792922\n",
      "Epoch 58100: loss = 68.91458011756454\n",
      "Epoch 58200: loss = 68.89574371614985\n",
      "Epoch 58300: loss = 68.87697288205096\n",
      "Epoch 58400: loss = 68.85825728814046\n",
      "Epoch 58500: loss = 68.8395927463251\n",
      "Epoch 58600: loss = 68.82100515601955\n",
      "Epoch 58700: loss = 68.80252362476605\n",
      "Epoch 58800: loss = 68.7841167499438\n",
      "Epoch 58900: loss = 68.76578655966043\n",
      "Epoch 59000: loss = 68.74752405420666\n",
      "Epoch 59100: loss = 68.72933016657609\n",
      "Epoch 59200: loss = 68.71121283473201\n",
      "Epoch 59300: loss = 68.69319647384273\n",
      "Epoch 59400: loss = 68.67523367508603\n",
      "Epoch 59500: loss = 68.65732238322033\n",
      "Epoch 59600: loss = 68.63948002156155\n",
      "Epoch 59700: loss = 68.62170976378214\n",
      "Epoch 59800: loss = 68.60401722500737\n",
      "Epoch 59900: loss = 68.58644269907795\n",
      "Epoch 60000: loss = 68.56894032303052\n",
      "Epoch 60100: loss = 68.55150171247112\n",
      "Epoch 60200: loss = 68.53411973519297\n",
      "Epoch 60300: loss = 68.51679622776052\n",
      "Epoch 60400: loss = 68.49952612075674\n",
      "Epoch 60500: loss = 68.48230263819212\n",
      "Epoch 60600: loss = 68.46514847605067\n",
      "Epoch 60700: loss = 68.44804592560311\n",
      "Epoch 60800: loss = 68.43099049247185\n",
      "Epoch 60900: loss = 68.41400521831635\n",
      "Epoch 61000: loss = 68.3970823139961\n",
      "Epoch 61100: loss = 68.38023092517322\n",
      "Epoch 61200: loss = 68.36343879071632\n",
      "Epoch 61300: loss = 68.34672308454688\n",
      "Epoch 61400: loss = 68.33006946841381\n",
      "Epoch 61500: loss = 68.31346383499053\n",
      "Epoch 61600: loss = 68.29691265896724\n",
      "Epoch 61700: loss = 68.280418198289\n",
      "Epoch 61800: loss = 68.26397900276316\n",
      "Epoch 61900: loss = 68.2476023762412\n",
      "Epoch 62000: loss = 68.23129045232977\n",
      "Epoch 62100: loss = 68.21503468301005\n",
      "Epoch 62200: loss = 68.1988459262281\n",
      "Epoch 62300: loss = 68.18271228636453\n",
      "Epoch 62400: loss = 68.16668536308981\n",
      "Epoch 62500: loss = 68.15072031504498\n",
      "Epoch 62600: loss = 68.13481995915826\n",
      "Epoch 62700: loss = 68.11897522687082\n",
      "Epoch 62800: loss = 68.10317237465259\n",
      "Epoch 62900: loss = 68.08741350959856\n",
      "Epoch 63000: loss = 68.07170898684451\n",
      "Epoch 63100: loss = 68.05607836969034\n",
      "Epoch 63200: loss = 68.04051566425086\n",
      "Epoch 63300: loss = 68.02500080750744\n",
      "Epoch 63400: loss = 68.0095312011694\n",
      "Epoch 63500: loss = 67.99410177051752\n",
      "Epoch 63600: loss = 67.97871302823603\n",
      "Epoch 63700: loss = 67.96337646455316\n",
      "Epoch 63800: loss = 67.94808236902004\n",
      "Epoch 63900: loss = 67.9328543563849\n",
      "Epoch 64000: loss = 67.91767407551913\n",
      "Epoch 64100: loss = 67.9025408621964\n",
      "Epoch 64200: loss = 67.8874615983392\n",
      "Epoch 64300: loss = 67.87244232172496\n",
      "Epoch 64400: loss = 67.85746786275378\n",
      "Epoch 64500: loss = 67.84254664017112\n",
      "Epoch 64600: loss = 67.82768878907243\n",
      "Epoch 64700: loss = 67.81286931743345\n",
      "Epoch 64800: loss = 67.7980882835931\n",
      "Epoch 64900: loss = 67.78335005104101\n",
      "Epoch 65000: loss = 67.76866859448381\n",
      "Epoch 65100: loss = 67.7540860513082\n",
      "Epoch 65200: loss = 67.73955460642156\n",
      "Epoch 65300: loss = 67.7250985780736\n",
      "Epoch 65400: loss = 67.71071650803822\n",
      "Epoch 65500: loss = 67.69637822122415\n",
      "Epoch 65600: loss = 67.68208437207447\n",
      "Epoch 65700: loss = 67.66783812255919\n",
      "Epoch 65800: loss = 67.65364202480944\n",
      "Epoch 65900: loss = 67.63950558300272\n",
      "Epoch 66000: loss = 67.62541349725777\n",
      "Epoch 66100: loss = 67.61137487009773\n",
      "Epoch 66200: loss = 67.59737932258781\n",
      "Epoch 66300: loss = 67.58343158513284\n",
      "Epoch 66400: loss = 67.5695232395623\n",
      "Epoch 66500: loss = 67.55564557554149\n",
      "Epoch 66600: loss = 67.54179939820894\n",
      "Epoch 66700: loss = 67.52799589101332\n",
      "Epoch 66800: loss = 67.51425632071724\n",
      "Epoch 66900: loss = 67.50056218343005\n",
      "Epoch 67000: loss = 67.48693384447742\n",
      "Epoch 67100: loss = 67.47335936831288\n",
      "Epoch 67200: loss = 67.45982624381682\n",
      "Epoch 67300: loss = 67.44633107433229\n",
      "Epoch 67400: loss = 67.43290588258014\n",
      "Epoch 67500: loss = 67.4195225348335\n",
      "Epoch 67600: loss = 67.40618758260777\n",
      "Epoch 67700: loss = 67.39288729214499\n",
      "Epoch 67800: loss = 67.37961301195246\n",
      "Epoch 67900: loss = 67.36637352326788\n",
      "Epoch 68000: loss = 67.35317062513441\n",
      "Epoch 68100: loss = 67.34000940637128\n",
      "Epoch 68200: loss = 67.3269767418052\n",
      "Epoch 68300: loss = 67.31397648457228\n",
      "Epoch 68400: loss = 67.30101760048224\n",
      "Epoch 68500: loss = 67.28811078676046\n",
      "Epoch 68600: loss = 67.27524338158051\n",
      "Epoch 68700: loss = 67.26240474075348\n",
      "Epoch 68800: loss = 67.24959672011781\n",
      "Epoch 68900: loss = 67.23682925769\n",
      "Epoch 69000: loss = 67.22410003895314\n",
      "Epoch 69100: loss = 67.21140494987426\n",
      "Epoch 69200: loss = 67.19874064635638\n",
      "Epoch 69300: loss = 67.1861271901127\n",
      "Epoch 69400: loss = 67.1735616185509\n",
      "Epoch 69500: loss = 67.1610349489903\n",
      "Epoch 69600: loss = 67.14854402638636\n",
      "Epoch 69700: loss = 67.13609797264255\n",
      "Epoch 69800: loss = 67.12369745805724\n",
      "Epoch 69900: loss = 67.11133152799218\n",
      "Epoch 70000: loss = 67.09900112898568\n",
      "Epoch 70100: loss = 67.08671431496674\n",
      "Epoch 70200: loss = 67.07447843987603\n",
      "Epoch 70300: loss = 67.06229347860402\n",
      "Epoch 70400: loss = 67.05013608758506\n",
      "Epoch 70500: loss = 67.03800421769176\n",
      "Epoch 70600: loss = 67.02590586703079\n",
      "Epoch 70700: loss = 67.0138439040652\n",
      "Epoch 70800: loss = 67.0018200768118\n",
      "Epoch 70900: loss = 66.9898498458607\n",
      "Epoch 71000: loss = 66.97792986523554\n",
      "Epoch 71100: loss = 66.96604130968132\n",
      "Epoch 71200: loss = 66.95418602382242\n",
      "Epoch 71300: loss = 66.9423577936797\n",
      "Epoch 71400: loss = 66.93056928100314\n",
      "Epoch 71500: loss = 66.91883813165205\n",
      "Epoch 71600: loss = 66.90716493408262\n",
      "Epoch 71700: loss = 66.89551412534067\n",
      "Epoch 71800: loss = 66.88389283138326\n",
      "Epoch 71900: loss = 66.87229918097623\n",
      "Epoch 72000: loss = 66.86074276789194\n",
      "Epoch 72100: loss = 66.8492211064816\n",
      "Epoch 72200: loss = 66.83773577143663\n",
      "Epoch 72300: loss = 66.8262828353797\n",
      "Epoch 72400: loss = 66.8148564549653\n",
      "Epoch 72500: loss = 66.80345402613618\n",
      "Epoch 72600: loss = 66.7920782033421\n",
      "Epoch 72700: loss = 66.78073289166697\n",
      "Epoch 72800: loss = 66.76942272829407\n",
      "Epoch 72900: loss = 66.75816819313371\n",
      "Epoch 73000: loss = 66.74694246344446\n",
      "Epoch 73100: loss = 66.73575050742258\n",
      "Epoch 73200: loss = 66.72458402769045\n",
      "Epoch 73300: loss = 66.71345758017583\n",
      "Epoch 73400: loss = 66.70236988549306\n",
      "Epoch 73500: loss = 66.69131336345043\n",
      "Epoch 73600: loss = 66.68028863395072\n",
      "Epoch 73700: loss = 66.66930164239199\n",
      "Epoch 73800: loss = 66.6583488203273\n",
      "Epoch 73900: loss = 66.64743873606714\n",
      "Epoch 74000: loss = 66.63657609603594\n",
      "Epoch 74100: loss = 66.62573611388862\n",
      "Epoch 74200: loss = 66.61492055787555\n",
      "Epoch 74300: loss = 66.60414474472337\n",
      "Epoch 74400: loss = 66.5934089666836\n",
      "Epoch 74500: loss = 66.58270095519069\n",
      "Epoch 74600: loss = 66.57203427780863\n",
      "Epoch 74700: loss = 66.56139922753775\n",
      "Epoch 74800: loss = 66.5507918629174\n",
      "Epoch 74900: loss = 66.54021709063123\n",
      "Epoch 75000: loss = 66.52966940197724\n",
      "Epoch 75100: loss = 66.51916749672714\n",
      "Epoch 75200: loss = 66.50872116194094\n",
      "Epoch 75300: loss = 66.49829498254124\n",
      "Epoch 75400: loss = 66.48788796855206\n",
      "Epoch 75500: loss = 66.47749915584524\n",
      "Epoch 75600: loss = 66.46713624335412\n",
      "Epoch 75700: loss = 66.45680941783844\n",
      "Epoch 75800: loss = 66.44651160854252\n",
      "Epoch 75900: loss = 66.43623494260446\n",
      "Epoch 76000: loss = 66.42598489047796\n",
      "Epoch 76100: loss = 66.41576346006366\n",
      "Epoch 76200: loss = 66.40557430081303\n",
      "Epoch 76300: loss = 66.39540957509443\n",
      "Epoch 76400: loss = 66.38527226300586\n",
      "Epoch 76500: loss = 66.37516070159515\n",
      "Epoch 76600: loss = 66.36507391638871\n",
      "Epoch 76700: loss = 66.35503449037847\n",
      "Epoch 76800: loss = 66.34504228063898\n",
      "Epoch 76900: loss = 66.33507087750431\n",
      "Epoch 77000: loss = 66.32511927847546\n",
      "Epoch 77100: loss = 66.31519181709643\n",
      "Epoch 77200: loss = 66.30529013256665\n",
      "Epoch 77300: loss = 66.29541041947648\n",
      "Epoch 77400: loss = 66.28555838332338\n",
      "Epoch 77500: loss = 66.27574339185202\n",
      "Epoch 77600: loss = 66.26595079367763\n",
      "Epoch 77700: loss = 66.2561929242632\n",
      "Epoch 77800: loss = 66.24647143736259\n",
      "Epoch 77900: loss = 66.23677570293728\n",
      "Epoch 78000: loss = 66.22711060456889\n",
      "Epoch 78100: loss = 66.21746897764453\n",
      "Epoch 78200: loss = 66.20785508387583\n",
      "Epoch 78300: loss = 66.19828572469477\n",
      "Epoch 78400: loss = 66.18873864184906\n",
      "Epoch 78500: loss = 66.17921417665576\n",
      "Epoch 78600: loss = 66.16970976521839\n",
      "Epoch 78700: loss = 66.16023301814211\n",
      "Epoch 78800: loss = 66.15078660381468\n",
      "Epoch 78900: loss = 66.1413600136044\n",
      "Epoch 79000: loss = 66.13195523633527\n",
      "Epoch 79100: loss = 66.12257649617018\n",
      "Epoch 79200: loss = 66.11323500188524\n",
      "Epoch 79300: loss = 66.10397113447391\n",
      "Epoch 79400: loss = 66.09472936353865\n",
      "Epoch 79500: loss = 66.08550791421783\n",
      "Epoch 79600: loss = 66.07631298929996\n",
      "Epoch 79700: loss = 66.06713841804692\n",
      "Epoch 79800: loss = 66.05798093936085\n",
      "Epoch 79900: loss = 66.04884641703246\n",
      "Epoch 80000: loss = 66.03974590950918\n",
      "Epoch 80100: loss = 66.03066925345789\n",
      "Epoch 80200: loss = 66.02161115087175\n",
      "Epoch 80300: loss = 66.01257418826283\n",
      "Epoch 80400: loss = 66.0035686236036\n",
      "Epoch 80500: loss = 65.99458965178374\n",
      "Epoch 80600: loss = 65.98562671479355\n",
      "Epoch 80700: loss = 65.97668086297986\n",
      "Epoch 80800: loss = 65.96775384704827\n",
      "Epoch 80900: loss = 65.95885305765366\n",
      "Epoch 81000: loss = 65.9499768122017\n",
      "Epoch 81100: loss = 65.94113264134668\n",
      "Epoch 81200: loss = 65.93232635948507\n",
      "Epoch 81300: loss = 65.92354193925125\n",
      "Epoch 81400: loss = 65.91477379443647\n",
      "Epoch 81500: loss = 65.90602498198999\n",
      "Epoch 81600: loss = 65.89729504891329\n",
      "Epoch 81700: loss = 65.88859151365799\n",
      "Epoch 81800: loss = 65.87991278506814\n",
      "Epoch 81900: loss = 65.87125133936702\n",
      "Epoch 82000: loss = 65.86261063671334\n",
      "Epoch 82100: loss = 65.85399333704275\n",
      "Epoch 82200: loss = 65.84540347534895\n",
      "Epoch 82300: loss = 65.83683270667338\n",
      "Epoch 82400: loss = 65.82828073283684\n",
      "Epoch 82500: loss = 65.81974515100482\n",
      "Epoch 82600: loss = 65.81122741481796\n",
      "Epoch 82700: loss = 65.80273055385436\n",
      "Epoch 82800: loss = 65.79425140726323\n",
      "Epoch 82900: loss = 65.78579307153439\n",
      "Epoch 83000: loss = 65.77735723834687\n",
      "Epoch 83100: loss = 65.76894468690932\n",
      "Epoch 83200: loss = 65.76054974528132\n",
      "Epoch 83300: loss = 65.75217899590452\n",
      "Epoch 83400: loss = 65.74382974021798\n",
      "Epoch 83500: loss = 65.73549683693284\n",
      "Epoch 83600: loss = 65.72719060701448\n",
      "Epoch 83700: loss = 65.71891735358132\n",
      "Epoch 83800: loss = 65.71070461783017\n",
      "Epoch 83900: loss = 65.70250876083382\n",
      "Epoch 84000: loss = 65.69433023249921\n",
      "Epoch 84100: loss = 65.68617130236812\n",
      "Epoch 84200: loss = 65.67803997498777\n",
      "Epoch 84300: loss = 65.66993274563616\n",
      "Epoch 84400: loss = 65.6618458054087\n",
      "Epoch 84500: loss = 65.65378031066793\n",
      "Epoch 84600: loss = 65.64574744567638\n",
      "Epoch 84700: loss = 65.63773451465381\n",
      "Epoch 84800: loss = 65.62973722301675\n",
      "Epoch 84900: loss = 65.62176537630552\n",
      "Epoch 85000: loss = 65.61382336854302\n",
      "Epoch 85100: loss = 65.60590764353209\n",
      "Epoch 85200: loss = 65.59801739781496\n",
      "Epoch 85300: loss = 65.59014643637775\n",
      "Epoch 85400: loss = 65.58230724374017\n",
      "Epoch 85500: loss = 65.57448496438231\n",
      "Epoch 85600: loss = 65.56667784895168\n",
      "Epoch 85700: loss = 65.55888919943915\n",
      "Epoch 85800: loss = 65.55111809103745\n",
      "Epoch 85900: loss = 65.54336830935554\n",
      "Epoch 86000: loss = 65.53564741442274\n",
      "Epoch 86100: loss = 65.52794048546913\n",
      "Epoch 86200: loss = 65.52024732741604\n",
      "Epoch 86300: loss = 65.51256703792639\n",
      "Epoch 86400: loss = 65.50490614977505\n",
      "Epoch 86500: loss = 65.49726130536652\n",
      "Epoch 86600: loss = 65.48963315962177\n",
      "Epoch 86700: loss = 65.4820205080226\n",
      "Epoch 86800: loss = 65.47442109974462\n",
      "Epoch 86900: loss = 65.46683569773327\n",
      "Epoch 87000: loss = 65.45926543581385\n",
      "Epoch 87100: loss = 65.45172055472825\n",
      "Epoch 87200: loss = 65.44420365762434\n",
      "Epoch 87300: loss = 65.43670745418342\n",
      "Epoch 87400: loss = 65.42922486557698\n",
      "Epoch 87500: loss = 65.42175595796961\n",
      "Epoch 87600: loss = 65.41430881572938\n",
      "Epoch 87700: loss = 65.40687996989932\n",
      "Epoch 87800: loss = 65.39946768046113\n",
      "Epoch 87900: loss = 65.39207256726294\n",
      "Epoch 88000: loss = 65.38469636229627\n",
      "Epoch 88100: loss = 65.3773403833718\n",
      "Epoch 88200: loss = 65.36999861204139\n",
      "Epoch 88300: loss = 65.36267256220687\n",
      "Epoch 88400: loss = 65.35536575036232\n",
      "Epoch 88500: loss = 65.34809866384938\n",
      "Epoch 88600: loss = 65.34084734165491\n",
      "Epoch 88700: loss = 65.33360895328666\n",
      "Epoch 88800: loss = 65.32639840419255\n",
      "Epoch 88900: loss = 65.31924450384979\n",
      "Epoch 89000: loss = 65.31210895034046\n",
      "Epoch 89100: loss = 65.30498633924093\n",
      "Epoch 89200: loss = 65.29787666959383\n",
      "Epoch 89300: loss = 65.29078366463594\n",
      "Epoch 89400: loss = 65.28370309175298\n",
      "Epoch 89500: loss = 65.27663714821118\n",
      "Epoch 89600: loss = 65.26958467716746\n",
      "Epoch 89700: loss = 65.26254800822349\n",
      "Epoch 89800: loss = 65.25552572351023\n",
      "Epoch 89900: loss = 65.24852648008056\n",
      "Epoch 90000: loss = 65.24154328894701\n",
      "Epoch 90100: loss = 65.23457289739099\n",
      "Epoch 90200: loss = 65.22761480096581\n",
      "Epoch 90300: loss = 65.22067180609952\n",
      "Epoch 90400: loss = 65.21374705833634\n",
      "Epoch 90500: loss = 65.20683948813607\n",
      "Epoch 90600: loss = 65.19995873043294\n",
      "Epoch 90700: loss = 65.19309967290124\n",
      "Epoch 90800: loss = 65.18625852565812\n",
      "Epoch 90900: loss = 65.17942932570668\n",
      "Epoch 91000: loss = 65.17261127463391\n",
      "Epoch 91100: loss = 65.16580789269844\n",
      "Epoch 91200: loss = 65.15902530545821\n",
      "Epoch 91300: loss = 65.15225229452454\n",
      "Epoch 91400: loss = 65.14549078670206\n",
      "Epoch 91500: loss = 65.13874027486645\n",
      "Epoch 91600: loss = 65.13200083604544\n",
      "Epoch 91700: loss = 65.12527566320671\n",
      "Epoch 91800: loss = 65.11856239216581\n",
      "Epoch 91900: loss = 65.11185956275557\n",
      "Epoch 92000: loss = 65.10516907254038\n",
      "Epoch 92100: loss = 65.09849199184552\n",
      "Epoch 92200: loss = 65.09182641770977\n",
      "Epoch 92300: loss = 65.08517294615652\n",
      "Epoch 92400: loss = 65.07853141689735\n",
      "Epoch 92500: loss = 65.07190375322158\n",
      "Epoch 92600: loss = 65.0652893426821\n",
      "Epoch 92700: loss = 65.05869956892815\n",
      "Epoch 92800: loss = 65.05212628783858\n",
      "Epoch 92900: loss = 65.0455675590177\n",
      "Epoch 93000: loss = 65.03901915912948\n",
      "Epoch 93100: loss = 65.03248130585976\n",
      "Epoch 93200: loss = 65.02595679927961\n",
      "Epoch 93300: loss = 65.01944884574996\n",
      "Epoch 93400: loss = 65.01297351278556\n",
      "Epoch 93500: loss = 65.00651141185466\n",
      "Epoch 93600: loss = 65.00006060798707\n",
      "Epoch 93700: loss = 64.99362160997592\n",
      "Epoch 93800: loss = 64.98720118723888\n",
      "Epoch 93900: loss = 64.98080672794356\n",
      "Epoch 94000: loss = 64.97442702341834\n",
      "Epoch 94100: loss = 64.96805754739889\n",
      "Epoch 94200: loss = 64.96170022119468\n",
      "Epoch 94300: loss = 64.95536558234613\n",
      "Epoch 94400: loss = 64.94904387560577\n",
      "Epoch 94500: loss = 64.94273894987535\n",
      "Epoch 94600: loss = 64.93644522569888\n",
      "Epoch 94700: loss = 64.93017263183086\n",
      "Epoch 94800: loss = 64.92394829102562\n",
      "Epoch 94900: loss = 64.91773388298888\n",
      "Epoch 95000: loss = 64.91152771344116\n",
      "Epoch 95100: loss = 64.90533221548857\n",
      "Epoch 95200: loss = 64.89914588137788\n",
      "Epoch 95300: loss = 64.89297198475495\n",
      "Epoch 95400: loss = 64.88680854154364\n",
      "Epoch 95500: loss = 64.88065745324049\n",
      "Epoch 95600: loss = 64.87451621325643\n",
      "Epoch 95700: loss = 64.86838911381109\n",
      "Epoch 95800: loss = 64.86227608128989\n",
      "Epoch 95900: loss = 64.85617738799391\n",
      "Epoch 96000: loss = 64.85009668778208\n",
      "Epoch 96100: loss = 64.84402534343157\n",
      "Epoch 96200: loss = 64.83796266573053\n",
      "Epoch 96300: loss = 64.83191290675555\n",
      "Epoch 96400: loss = 64.82588240263956\n",
      "Epoch 96500: loss = 64.81986369788764\n",
      "Epoch 96600: loss = 64.81385523972529\n",
      "Epoch 96700: loss = 64.80785680630022\n",
      "Epoch 96800: loss = 64.80186864712805\n",
      "Epoch 96900: loss = 64.79589395311977\n",
      "Epoch 97000: loss = 64.78995364242574\n",
      "Epoch 97100: loss = 64.78402604743091\n",
      "Epoch 97200: loss = 64.77810713822439\n",
      "Epoch 97300: loss = 64.77219751162423\n",
      "Epoch 97400: loss = 64.76629674197075\n",
      "Epoch 97500: loss = 64.76041931316584\n",
      "Epoch 97600: loss = 64.75455706697018\n",
      "Epoch 97700: loss = 64.74870411212616\n",
      "Epoch 97800: loss = 64.74286324320634\n",
      "Epoch 97900: loss = 64.73703364598289\n",
      "Epoch 98000: loss = 64.73121387960892\n",
      "Epoch 98100: loss = 64.72540416451324\n",
      "Epoch 98200: loss = 64.71960650422204\n",
      "Epoch 98300: loss = 64.71382515705031\n",
      "Epoch 98400: loss = 64.70806195707353\n",
      "Epoch 98500: loss = 64.70231379738514\n",
      "Epoch 98600: loss = 64.69657602692732\n",
      "Epoch 98700: loss = 64.69085054855186\n",
      "Epoch 98800: loss = 64.6851486812117\n",
      "Epoch 98900: loss = 64.67945662453891\n",
      "Epoch 99000: loss = 64.67377245298616\n",
      "Epoch 99100: loss = 64.6680957878256\n",
      "Epoch 99200: loss = 64.66242981948018\n",
      "Epoch 99300: loss = 64.65678521226043\n",
      "Epoch 99400: loss = 64.65115012434863\n",
      "Epoch 99500: loss = 64.64552587065431\n",
      "Epoch 99600: loss = 64.63991836929583\n",
      "Epoch 99700: loss = 64.63431890866667\n",
      "Epoch 99800: loss = 64.62872780277061\n",
      "Epoch 99900: loss = 64.62314886110579\n",
      "Epoch 100000: loss = 64.61758053685735\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "step_size = 5e-7\n",
    "for i in range(epochs):\n",
    "    objective = objective_function_4(u, v, w)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ' + str(i) + \": loss = \" + str(float(objective)))\n",
    "    objective.backward()\n",
    "    with torch.no_grad():\n",
    "        u -= u.grad * step_size\n",
    "        v -= v.grad * step_size\n",
    "        w -= w.grad * step_size\n",
    "        u.grad.zero_()\n",
    "        v.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "print('Epoch ' + str(epochs) + \": loss = \" + str(float(objective_function_4(u, v, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff52d606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8968e-01],\n",
      "        [-1.9470e-01],\n",
      "        [-1.9246e-01],\n",
      "        [-1.8523e-01],\n",
      "        [-1.8881e-01],\n",
      "        [-1.8616e-01],\n",
      "        [-1.8903e-01],\n",
      "        [-1.9253e-01],\n",
      "        [-1.8896e-01],\n",
      "        [-1.8987e-01],\n",
      "        [-1.8979e-01],\n",
      "        [-1.8810e-01],\n",
      "        [-1.9353e-01],\n",
      "        [-1.9275e-01],\n",
      "        [-1.8852e-01],\n",
      "        [-1.8480e-01],\n",
      "        [-1.8738e-01],\n",
      "        [-1.8726e-01],\n",
      "        [-1.8427e-01],\n",
      "        [-1.8886e-01],\n",
      "        [-1.8839e-01],\n",
      "        [-1.8951e-01],\n",
      "        [-1.8717e-01],\n",
      "        [-1.8802e-01],\n",
      "        [-1.8620e-01],\n",
      "        [ 7.1323e-04],\n",
      "        [ 2.6336e-03],\n",
      "        [-1.4971e-03],\n",
      "        [ 1.1622e-03],\n",
      "        [ 3.1174e-03],\n",
      "        [-1.0930e-03],\n",
      "        [-8.3965e-04],\n",
      "        [ 9.5510e-04],\n",
      "        [-1.6278e-03],\n",
      "        [ 3.9801e-04],\n",
      "        [-2.2459e-04],\n",
      "        [ 1.4306e-04],\n",
      "        [-2.1572e-03],\n",
      "        [-5.3418e-04],\n",
      "        [ 4.0877e-03],\n",
      "        [-1.0766e-03],\n",
      "        [ 3.3342e-03],\n",
      "        [ 1.6348e-03],\n",
      "        [-7.9632e-04],\n",
      "        [ 3.1910e-03],\n",
      "        [ 5.8155e-03],\n",
      "        [ 4.4799e-03],\n",
      "        [-3.4546e-03],\n",
      "        [ 2.6693e-03],\n",
      "        [ 3.8365e-04]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(v * v - w * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547a75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
